{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29de1d89",
   "metadata": {},
   "source": [
    "# Applied Natural Language Processing 955G5\n",
    "## Computer Based Examination, January 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297731e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### update your candidate number here\n",
    "candidate_number=200816"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230e5810",
   "metadata": {},
   "source": [
    "## Question 2 (50 marks total)\n",
    "This question is about Naïve Bayes classification.\n",
    "\n",
    "In a collection of 10 documents, 4 are labelled by a human as being \"relevant_to_AI\" and 6 are labelled by the human as being \"not_relevant_to_AI\".  This data is stored in `classes` and displayed in the class_df dataframe below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9443051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relevant_to_AI</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not_relevant_to_AI</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class  count\n",
       "0      relevant_to_AI      4\n",
       "1  not_relevant_to_AI      6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###do not change the code in this cell;\n",
    "\n",
    "import pandas as pd\n",
    "classes={\"relevant_to_AI\":4, \"not_relevant_to_AI\":6}\n",
    "class_conditionals={\"relevant_to_AI\":{\"artificial\":15,\"intelligence\":15,\"learning\":10,\"robot\":5,\"wins\":1,\"fly\":2,\"chess\":2,\"garden\":0,\"maintenance\":0,\"bumblebee\":0,\"house\":0},\"not_relevant_to_AI\":{\"artificial\":6,\"intelligence\":2,\"learning\":2,\"robot\":0,\"chess\":3,\"wins\":5,\"fly\":2,\"garden\":20,\"maintenance\":15,\"bumblebee\":5,\"house\":40}}\n",
    "                    \n",
    "class_df=pd.DataFrame(list(classes.items()),columns=[\"class\",\"count\"])\n",
    "class_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbfa5e7",
   "metadata": {},
   "source": [
    "`class_conditionals` stores the frequencies of each word in a restricted vocabulary in documents belonging to a a certain class. This is displayed in the `cc_df` dataframe below.  For example, the word *artificial* occurs 15 times in documents labelled as being `relevant_to_AI` and 6 times in documents labelled as being `not_relevant_to_AI` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877eaa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevant_to_AI</th>\n",
       "      <th>not_relevant_to_AI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>artificial</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intelligence</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robot</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wins</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fly</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chess</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>garden</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maintenance</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bumblebee</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              relevant_to_AI  not_relevant_to_AI\n",
       "artificial                15                   6\n",
       "intelligence              15                   2\n",
       "learning                  10                   2\n",
       "robot                      5                   0\n",
       "wins                       1                   5\n",
       "fly                        2                   2\n",
       "chess                      2                   3\n",
       "garden                     0                  20\n",
       "maintenance                0                  15\n",
       "bumblebee                  0                   5\n",
       "house                      0                  40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### do not change the code in this cell\n",
    "cc_df=pd.DataFrame(class_conditionals)\n",
    "cc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe15c15",
   "metadata": {},
   "source": [
    "a) Imagine that a document is picked at random and a word is picked at random from that document.  Let C be the class of the selected document and F be the selected word.  Using information from the two tables, calculate (either by hand or using code) the following probability estimates:\n",
    "\n",
    "i) P(C=\"relevant_to_AI\")\n",
    "\n",
    "ii) P(F=\"learning\")\n",
    "\n",
    "iii) P(F = \"learning\", C= \"relevant_to_AI\")\n",
    "\n",
    "iv) P(F = \"learning\" | C = \"relevant_to_AI\")\n",
    "\n",
    "v) P(C = \"relevant_to_AI\" | F = \"learning\")\n",
    "\n",
    "[10 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5119163",
   "metadata": {},
   "source": [
    "a) i) p(relevant to AI) = 4 / 4 + 6 = 0.4\n",
    "\n",
    "ii) p(learning) = (10 / 50) * 0.4 + (2 / 100) * 0.6 = 0.092\n",
    "\n",
    "iii) p(learning and relevant to AI) = (10 / 50) * 0.4 = 0.08\n",
    "\n",
    "iv) p(learning given relevant to AI) = p(learning and relevant to AI) / p(relevant to AI) = 0.08 / 0.4 = 0.2\n",
    "\n",
    "v) p(relevant to AI given learning) = p(learning and relevant to AI) / p(learning) = 0.08 / 0.092 = 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d216f7",
   "metadata": {},
   "source": [
    "b) Write code to turn the frequency distributions in `classes` and `class_conditionals` into the corresponding probability distributions required for a Naïve Bayes classifier.  Display the results either as dictionaries or in a dataframe.\n",
    "[8 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0c1e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relevant_to_AI': 0.4, 'not_relevant_to_AI': 0.6}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes['relevant_to_AI'] = 0.4\n",
    "classes['not_relevant_to_AI'] = 0.6\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02351be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'artificial': 15,\n",
       "   'intelligence': 15,\n",
       "   'learning': 10,\n",
       "   'robot': 5,\n",
       "   'wins': 1,\n",
       "   'fly': 2,\n",
       "   'chess': 2,\n",
       "   'garden': 0,\n",
       "   'maintenance': 0,\n",
       "   'bumblebee': 0,\n",
       "   'house': 0},\n",
       "  'relevant_to_AI'),\n",
       " ({'artificial': 6,\n",
       "   'intelligence': 2,\n",
       "   'learning': 2,\n",
       "   'robot': 0,\n",
       "   'chess': 3,\n",
       "   'wins': 5,\n",
       "   'fly': 2,\n",
       "   'garden': 20,\n",
       "   'maintenance': 15,\n",
       "   'bumblebee': 5,\n",
       "   'house': 40},\n",
       "  'not_relevant_to_AI')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cc = []\n",
    "new_cc.append((class_conditionals['relevant_to_AI'], 'relevant_to_AI'))\n",
    "new_cc.append((class_conditionals['not_relevant_to_AI'], 'not_relevant_to_AI'))\n",
    "new_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f86043c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_probs(data):\n",
    "    conds={}\n",
    "    for(doc,label) in data:\n",
    "        classcond=conds.get(label,{})\n",
    "        for word,value in doc.items():\n",
    "            classcond[word]=classcond.get(word,0)+value\n",
    "        \n",
    "        conds[label]=classcond\n",
    "    print(conds)\n",
    "    for label,dist in conds.items():\n",
    "        total=sum(dist.values())\n",
    "        conds[label]={key:value/total for (key,value) in dist.items()}\n",
    "        \n",
    "    return conds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17eb0a4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevant_to_AI': {'artificial': 15, 'intelligence': 15, 'learning': 10, 'robot': 5, 'wins': 1, 'fly': 2, 'chess': 2, 'garden': 0, 'maintenance': 0, 'bumblebee': 0, 'house': 0}, 'not_relevant_to_AI': {'artificial': 6, 'intelligence': 2, 'learning': 2, 'robot': 0, 'chess': 3, 'wins': 5, 'fly': 2, 'garden': 20, 'maintenance': 15, 'bumblebee': 5, 'house': 40}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relevant_to_AI': {'artificial': 0.3,\n",
       "  'intelligence': 0.3,\n",
       "  'learning': 0.2,\n",
       "  'robot': 0.1,\n",
       "  'wins': 0.02,\n",
       "  'fly': 0.04,\n",
       "  'chess': 0.04,\n",
       "  'garden': 0.0,\n",
       "  'maintenance': 0.0,\n",
       "  'bumblebee': 0.0,\n",
       "  'house': 0.0},\n",
       " 'not_relevant_to_AI': {'artificial': 0.06,\n",
       "  'intelligence': 0.02,\n",
       "  'learning': 0.02,\n",
       "  'robot': 0.0,\n",
       "  'chess': 0.03,\n",
       "  'wins': 0.05,\n",
       "  'fly': 0.02,\n",
       "  'garden': 0.2,\n",
       "  'maintenance': 0.15,\n",
       "  'bumblebee': 0.05,\n",
       "  'house': 0.4}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_probs = cond_probs(new_cc)\n",
    "cond_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f39ae16",
   "metadata": {},
   "source": [
    "c) Consider the following 3 sentences stored in `sents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdaee7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents=['An artificial bumblebee is learning to fly.','Robot wins at chess.','Robot causes traffic mayhem.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99955999",
   "metadata": {},
   "source": [
    "i) Write code which will tokenise the sentences, case normalise and remove punctuation and stopwords.  You may use library functions.  Store the result in sents_norm.\n",
    "\n",
    "[4 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4def383b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['An', 'artificial', 'bumblebee', 'is', 'learning', 'to', 'fly', '.'],\n",
       " ['Robot', 'wins', 'at', 'chess', '.'],\n",
       " ['Robot', 'causes', 'traffic', 'mayhem', '.']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sent_tokens = [word_tokenize(sent) for sent in sents]\n",
    "sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3360be07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['artificial', 'bumblebee', 'learning', 'fly'],\n",
       " ['robot', 'wins', 'chess'],\n",
       " ['robot', 'causes', 'traffic', 'mayhem']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "sents_norm = []\n",
    "for sent in sent_tokens:\n",
    "    filtered = []\n",
    "    tokens = [word for word in sent if word.isalpha()]\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    for w in tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered.append(w)\n",
    "    sents_norm.append(filtered)\n",
    "    \n",
    "sents_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f666307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artificial bumblebee learning fly',\n",
       " 'robot wins chess',\n",
       " 'robot causes traffic mayhem']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_norm2 = []\n",
    "for sent in sents_norm:\n",
    "    new_sent = ''\n",
    "    for word in sent:\n",
    "        new_sent += word\n",
    "        new_sent += ' '\n",
    "    new_sent = new_sent[:-1]\n",
    "    sents_norm2.append(new_sent)\n",
    "    \n",
    "sents_norm2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3bb888",
   "metadata": {},
   "source": [
    "ii) A Naïve Bayes classifier is initialised with prior and class conditional probability distributions according to the frequencies outlined in part a).   It is asked to predict the label of the 3 sentencess pre-processed and stored in `sents_norm`.  Using code (or otherwise), **determine** what prediction the classifier will make for each sentence.  **Explain** why the classifier makes the predictions that it does.\n",
    "\n",
    "[10 marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3fd196e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_121969/1421476262.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msents_norm2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_priors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_121969/1421476262.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(doc, priors, c_probs)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdoc_probs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpriors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mdoc_probs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mclasslabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msofar\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclasslabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclasslabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msofar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mhighprob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_121969/1421476262.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdoc_probs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpriors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mdoc_probs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mclasslabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msofar\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclasslabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclasslabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msofar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mhighprob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "def classify(doc,priors,c_probs):\n",
    "\n",
    "    #<put your definition of classify here>\n",
    "    doc_probs=priors\n",
    "    for word in doc.keys():            \n",
    "        doc_probs={classlabel:sofar*c_probs[classlabel].get(word,0) for (classlabel,sofar) in doc_probs.items()}\n",
    "\n",
    "    highprob=max(doc_probs.values())\n",
    "    print(doc_probs.values())\n",
    "    print(highprob)\n",
    "    classes=[c for c in doc_probs.keys() if doc_probs[c]==highprob]\n",
    "    print(classes)\n",
    "    return random.choice(classes)\n",
    "        \n",
    "c_priors = classes\n",
    "c_probs = cond_probs\n",
    "for sent in sents_norm2:\n",
    "    doc = FreqDist(sent.split())\n",
    "    classify(doc,c_priors,c_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3213b7",
   "metadata": {},
   "source": [
    "iii) Use code to recalculate the class_conditional probability distribution with add-one smoothing applied.\n",
    "[8 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c88bed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def known_vocabulary(data):\n",
    "    known=set()\n",
    "    for doc,label in data:\n",
    "        for word in list(doc.keys()):\n",
    "            known.add(word)\n",
    "    return known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1fd9046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artificial',\n",
       " 'bumblebee',\n",
       " 'chess',\n",
       " 'fly',\n",
       " 'garden',\n",
       " 'house',\n",
       " 'intelligence',\n",
       " 'learning',\n",
       " 'maintenance',\n",
       " 'robot',\n",
       " 'wins'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "vocab = known_vocabulary(new_cc)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1113ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_probs(data):\n",
    "    conds={}\n",
    "    for(doc,label) in data:\n",
    "        classcond=conds.get(label,{})\n",
    "        for word,value in doc.items():\n",
    "            classcond[word]=classcond.get(word,0)+value\n",
    "        \n",
    "        conds[label]=classcond\n",
    "\n",
    "    vocab=known_vocabulary(data)\n",
    "    for label, classcond in conds.items():\n",
    "        for word in vocab:\n",
    "        \n",
    "            classcond[word]=classcond.get(word,0)+1\n",
    "        conds[label]=classcond\n",
    "            \n",
    "    for label,dist in conds.items():\n",
    "        total=sum(dist.values())\n",
    "        conds[label]={key:value/total for (key,value) in dist.items()}\n",
    "        \n",
    "    return conds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "811015db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relevant_to_AI': {'artificial': 0.26229508196721313,\n",
       "  'intelligence': 0.26229508196721313,\n",
       "  'learning': 0.18032786885245902,\n",
       "  'robot': 0.09836065573770492,\n",
       "  'wins': 0.03278688524590164,\n",
       "  'fly': 0.04918032786885246,\n",
       "  'chess': 0.04918032786885246,\n",
       "  'garden': 0.01639344262295082,\n",
       "  'maintenance': 0.01639344262295082,\n",
       "  'bumblebee': 0.01639344262295082,\n",
       "  'house': 0.01639344262295082},\n",
       " 'not_relevant_to_AI': {'artificial': 0.06306306306306306,\n",
       "  'intelligence': 0.02702702702702703,\n",
       "  'learning': 0.02702702702702703,\n",
       "  'robot': 0.009009009009009009,\n",
       "  'chess': 0.036036036036036036,\n",
       "  'wins': 0.05405405405405406,\n",
       "  'fly': 0.02702702702702703,\n",
       "  'garden': 0.1891891891891892,\n",
       "  'maintenance': 0.14414414414414414,\n",
       "  'bumblebee': 0.05405405405405406,\n",
       "  'house': 0.36936936936936937}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_probs(new_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4b7c37",
   "metadata": {},
   "source": [
    "iv) Which of the predictions in part c)ii) would be different using the smoothed class_conditional probability distribution? Explain your answer.\n",
    "[5 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0b6763",
   "metadata": {},
   "source": [
    "We can see from our new conditional probabilities that all tokens have a value greater than 0, which prevents a prediction being 0 even if a token in the sentence has not been observed in a class before. \n",
    "\n",
    "We can therefore conclude that the first sentence in sents would have a non-zero probability because \"bumblebee\" now has a non-zero probability.\n",
    "\n",
    "The second string would also have a non-zero probability of being predicted as not relevant to AI, since the word robot now has a non-zero probability.\n",
    "\n",
    "The final string will, however, still be predicted to have probabilities 0 for both relevant and non relevant to AI. This is because the words traffic and mayhem are not in our known vocabulary, giving them probabilities of 0 each. We could resolve this by ignoring out of vocabulary words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d98a895",
   "metadata": {},
   "source": [
    "d) When considering the accuracy of different classifiers, explain why it is important for the class distribution to be balanced.\n",
    "[5 marks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ebf6b",
   "metadata": {},
   "source": [
    "When using accuracy as an evaluation metric, class balance is essential to avoiding misrepresention of the classes. E.g., a dataset with 2 classes that has 90% of its data assigned to one class would cause problems. If we built a supervised model to predict the classes of this dataset, the model can just predict the most frequent class all of the time, and be 90% correct on the whole dataset. This is known as class imbalance. The way to avoid this is by ensuring that your data has similar class distributions either by finding more data, or dropping some of the more frequently occuring classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce26c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
